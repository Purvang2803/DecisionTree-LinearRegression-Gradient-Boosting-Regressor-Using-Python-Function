{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2baf6b-4f06-4872-ba0a-4849e7b427c0",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0420d1af-a1d0-4a6e-b17b-052edbcbbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5ba23-72a9-4164-8fef-323842746d5c",
   "metadata": {},
   "source": [
    "### DecisionTree using Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59587d6b-39b1-46be-8e1c-9fe4e884ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def gini_index(self, groups, classes):\n",
    "        \"\"\"Calculate Gini Index for a split.\"\"\"\n",
    "        n_instances = float(sum(len(group) for group in groups))\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            for class_val in classes:\n",
    "                proportion = (group[:, -1] == class_val).sum() / size\n",
    "                score += proportion ** 2\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "\n",
    "    def test_split(self, index, value, dataset):\n",
    "        \"\"\"Split a dataset based on a feature and value.\"\"\"\n",
    "        left, right = [], []\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return np.array(left), np.array(right)\n",
    "\n",
    "    def get_split(self, dataset):\n",
    "        \"\"\"Find the best split for a dataset.\"\"\"\n",
    "        class_values = list(set(row[-1] for row in dataset))\n",
    "        best_index, best_value, best_score, best_groups = 999, 999, float(\"inf\"), None\n",
    "        for index in range(dataset.shape[1] - 1):\n",
    "            for row in dataset:\n",
    "                groups = self.test_split(index, row[index], dataset)\n",
    "                gini = self.gini_index(groups, class_values)\n",
    "                if gini < best_score:\n",
    "                    best_index, best_value, best_score, best_groups = index, row[index], gini, groups\n",
    "        return {\"index\": best_index, \"value\": best_value, \"groups\": best_groups}\n",
    "\n",
    "    def to_terminal(self, group):\n",
    "        \"\"\"Create a terminal node.\"\"\"\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "    def split(self, node, depth):\n",
    "        \"\"\"Create child splits for a node.\"\"\"\n",
    "        left, right = node[\"groups\"]\n",
    "        del node[\"groups\"]\n",
    "\n",
    "        # Handle cases where either left or right group is empty\n",
    "        if len(left) == 0:\n",
    "            node[\"left\"] = node[\"right\"] = self.to_terminal(right)\n",
    "            return\n",
    "        if len(right) == 0:\n",
    "            node[\"left\"] = node[\"right\"] = self.to_terminal(left)\n",
    "            return\n",
    "\n",
    "        # Check for max depth\n",
    "        if depth >= self.max_depth:\n",
    "            node[\"left\"], node[\"right\"] = self.to_terminal(left), self.to_terminal(right)\n",
    "            return\n",
    "\n",
    "        # Process left child\n",
    "        if len(left) <= self.min_samples_split:\n",
    "            node[\"left\"] = self.to_terminal(left)\n",
    "        else:\n",
    "            node[\"left\"] = self.get_split(left)\n",
    "            self.split(node[\"left\"], depth + 1)\n",
    "\n",
    "        # Process right child\n",
    "        if len(right) <= self.min_samples_split:\n",
    "            node[\"right\"] = self.to_terminal(right)\n",
    "        else:\n",
    "            node[\"right\"] = self.get_split(right)\n",
    "            self.split(node[\"right\"], depth + 1)\n",
    "\n",
    "    def build_tree(self, train):\n",
    "        \"\"\"Build the decision tree.\"\"\"\n",
    "        root = self.get_split(train)\n",
    "        self.split(root, 1)\n",
    "        return root\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the decision tree to the data.\"\"\"\n",
    "        dataset = np.column_stack((X, y))\n",
    "        self.tree = self.build_tree(dataset)\n",
    "\n",
    "    def predict_row(self, node, row):\n",
    "        \"\"\"Make a prediction for a single row.\"\"\"\n",
    "        if row[node[\"index\"]] < node[\"value\"]:\n",
    "            if isinstance(node[\"left\"], dict):\n",
    "                return self.predict_row(node[\"left\"], row)\n",
    "            else:\n",
    "                return node[\"left\"]\n",
    "        else:\n",
    "            if isinstance(node[\"right\"], dict):\n",
    "                return self.predict_row(node[\"right\"], row)\n",
    "            else:\n",
    "                return node[\"right\"]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions for a dataset.\"\"\"\n",
    "        return [self.predict_row(self.tree, row) for row in X]\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\DELL8\\\\OneDrive\\\\Pictures\\\\train.csv\", usecols=[\"Age\", \"Fare\"])\n",
    "df = df.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Create a target column for demonstration purposes\n",
    "# For example: classify as 1 if Fare > median, else 0\n",
    "df['Target'] = (df['Fare'] > df['Fare'].median()).astype(int)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df[[\"Age\", \"Fare\"]].values\n",
    "y = df[\"Target\"].values\n",
    "\n",
    "# Train the decision tree\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = tree.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbe8d05-b03c-416f-b064-777be2b0c14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age     Fare  Target  Predictions\n",
      "0    22.0   7.2500       0          0.0\n",
      "1    38.0  71.2833       1          1.0\n",
      "2    26.0   7.9250       0          0.0\n",
      "3    35.0  53.1000       1          1.0\n",
      "4    35.0   8.0500       0          0.0\n",
      "..    ...      ...     ...          ...\n",
      "885  39.0  29.1250       1          1.0\n",
      "886  27.0  13.0000       0          0.0\n",
      "887  19.0  30.0000       1          1.0\n",
      "889  26.0  30.0000       1          1.0\n",
      "890  32.0   7.7500       0          0.0\n",
      "\n",
      "[714 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "df[\"Predictions\"] = predictions\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094bf8e-76b0-44dc-8923-a293d05003ab",
   "metadata": {},
   "source": [
    "###  LinearRegression Using Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45222544-954f-4efb-8559-d26d258344cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.coefficients = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the linear regression model using the normal equation.\"\"\"\n",
    "        # Add a bias term (column of ones) to X\n",
    "        X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "        \n",
    "       \n",
    "        X_transpose = X.T\n",
    "        self.coefficients = np.linalg.inv(X_transpose @ X) @ X_transpose @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using the linear regression model.\"\"\"\n",
    "        \n",
    "        X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "        \n",
    "        # Predict using the coefficients\n",
    "        return X @ self.coefficients\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\DELL8\\\\OneDrive\\\\Pictures\\\\train.csv\", usecols=[\"Age\", \"Fare\"])\n",
    "df = df.dropna() \n",
    "df['Target'] = df['Fare']\n",
    "\n",
    "\n",
    "X = df[[\"Age\"]].values  \n",
    "y = df[\"Target\"].values \n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ad3f66-736b-43e3-b8d7-c885050f95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age     Fare   Target  Predictions\n",
      "0    22.0   7.2500   7.2500    32.000102\n",
      "1    38.0  71.2833  71.2833    37.599521\n",
      "2    26.0   7.9250   7.9250    33.399957\n",
      "3    35.0  53.1000  53.1000    36.549630\n",
      "4    35.0   8.0500   8.0500    36.549630\n",
      "..    ...      ...      ...          ...\n",
      "885  39.0  29.1250  29.1250    37.949485\n",
      "886  27.0  13.0000  13.0000    33.749921\n",
      "887  19.0  30.0000  30.0000    30.950211\n",
      "889  26.0  30.0000  30.0000    33.399957\n",
      "890  32.0   7.7500   7.7500    35.499739\n",
      "\n",
      "[714 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"Predictions\"] = predictions\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d0c18-64e8-48bb-886b-f473b64cbb9a",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor  Using Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e911674b-3b31-49f2-a42a-60273fda5464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\DELL8\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the Gradient Boosting model.\"\"\"\n",
    "       \n",
    "        predictions = np.full(y.shape, y.mean())\n",
    "        self.models = []\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "           \n",
    "            residuals = y - predictions\n",
    "            \n",
    "          \n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            self.models.append(tree)\n",
    "            \n",
    "            # Update predictions\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using the Gradient Boosting model.\"\"\"\n",
    "       \n",
    "        predictions = np.full((X.shape[0],), 0.0)\n",
    "        \n",
    "        for model in self.models:\n",
    "            predictions += self.learning_rate * model.predict(X)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit a decision tree to the data.\"\"\"\n",
    "        dataset = np.column_stack((X, y))\n",
    "        self.tree = self._build_tree(dataset, depth=0)\n",
    "\n",
    "    def _build_tree(self, dataset, depth):\n",
    "        \"\"\"Recursively build the decision tree.\"\"\"\n",
    "        if depth >= self.max_depth or len(dataset) <= 1:\n",
    "            return np.mean(dataset[:, -1])  # Return mean of target as leaf\n",
    "        \n",
    "        # Find the best split\n",
    "        best_split = self._get_best_split(dataset)\n",
    "        if not best_split:\n",
    "            return np.mean(dataset[:, -1])  # Return mean if no split improves the model\n",
    "        \n",
    "        left_tree = self._build_tree(best_split['left'], depth + 1)\n",
    "        right_tree = self._build_tree(best_split['right'], depth + 1)\n",
    "        return {'index': best_split['index'], 'value': best_split['value'], 'left': left_tree, 'right': right_tree}\n",
    "\n",
    "    def _get_best_split(self, dataset):\n",
    "        \"\"\"Find the best split for the dataset.\"\"\"\n",
    "        best_split = None\n",
    "        best_loss = float('inf')\n",
    "        for index in range(dataset.shape[1] - 1):\n",
    "            for value in dataset[:, index]:\n",
    "                left, right = self._split(dataset, index, value)\n",
    "                loss = self._calculate_loss(left, right)\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_split = {'index': index, 'value': value, 'left': left, 'right': right}\n",
    "        return best_split\n",
    "\n",
    "    def _split(self, dataset, index, value):\n",
    "        \"\"\"Split dataset into left and right based on a feature and value.\"\"\"\n",
    "        left = dataset[dataset[:, index] < value]\n",
    "        right = dataset[dataset[:, index] >= value]\n",
    "        return left, right\n",
    "\n",
    "    def _calculate_loss(self, left, right):\n",
    "        \"\"\"Calculate mean squared error loss for a split.\"\"\"\n",
    "        def mse(group):\n",
    "            if len(group) == 0:\n",
    "                return 0\n",
    "            return np.mean((group[:, -1] - np.mean(group[:, -1]))**2)\n",
    "        \n",
    "        return mse(left) * len(left) + mse(right) * len(right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using the decision tree.\"\"\"\n",
    "        return np.array([self._predict_row(self.tree, row) for row in X])\n",
    "\n",
    "    def _predict_row(self, node, row):\n",
    "        \"\"\"Predict a single row using the decision tree.\"\"\"\n",
    "        if isinstance(node, dict):\n",
    "            if row[node['index']] < node['value']:\n",
    "                return self._predict_row(node['left'], row)\n",
    "            else:\n",
    "                return self._predict_row(node['right'], row)\n",
    "        return node\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\DELL8\\\\OneDrive\\\\Pictures\\\\train.csv\", usecols=[\"Age\", \"Fare\"])\n",
    "df = df.dropna() \n",
    "df['Target'] = df['Fare']  \n",
    "X = df[[\"Age\"]].values  \n",
    "y = df[\"Target\"].values  \n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=10, learning_rate=0.1, max_depth=3)\n",
    "gbr.fit(X, y)\n",
    "\n",
    "\n",
    "predictions = gbr.predict(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3044ed36-9e49-49ea-b7a7-2084a7b8d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age     Fare   Target  Predictions\n",
      "0    22.0   7.2500   7.2500    -3.750592\n",
      "1    38.0  71.2833  71.2833     7.350557\n",
      "2    26.0   7.9250   7.9250    -6.063680\n",
      "3    35.0  53.1000  53.1000    35.573872\n",
      "4    35.0   8.0500   8.0500    35.573872\n",
      "..    ...      ...      ...          ...\n",
      "885  39.0  29.1250  29.1250     3.814389\n",
      "886  27.0  13.0000  13.0000    -5.671832\n",
      "887  19.0  30.0000  30.0000    -5.627645\n",
      "889  26.0  30.0000  30.0000    -6.063680\n",
      "890  32.0   7.7500   7.7500    -5.671832\n",
      "\n",
      "[714 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "df[\"Predictions\"] = predictions\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6fcac-5097-4ff6-ae21-3ff5f6ed5d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
